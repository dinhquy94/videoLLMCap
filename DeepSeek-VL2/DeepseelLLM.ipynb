{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058cb13-08ce-4890-8f28-9b95604b27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python get-pip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b0f553-b85e-47dd-9796-bbaa682e1e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 25.0.1 from /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages/pip (python 3.11)\n"
     ]
    }
   ],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d86b48-5aa0-417e-bbe2-cc7a93c16fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/quynd/vidCapLLM/DeepSeek-VL2\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch==2.0.1 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (2.0.1)\n",
      "Collecting transformers==4.38.2 (from deepseek_vl2==1.0.0)\n",
      "  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "Requirement already satisfied: timm>=0.9.16 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (1.0.15)\n",
      "Requirement already satisfied: xformers>=0.0.21 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (0.0.22)\n",
      "Requirement already satisfied: accelerate in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (1.4.0)\n",
      "Requirement already satisfied: sentencepiece in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (0.2.0)\n",
      "Requirement already satisfied: attrdict in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (2.0.1)\n",
      "Requirement already satisfied: einops in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from deepseek_vl2==1.0.0) (0.8.1)\n",
      "Requirement already satisfied: filelock in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torch==2.0.1->deepseek_vl2==1.0.0) (2.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2->deepseek_vl2==1.0.0)\n",
      "  Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from transformers==4.38.2->deepseek_vl2==1.0.0) (4.67.1)\n",
      "Requirement already satisfied: setuptools in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->deepseek_vl2==1.0.0) (76.0.0)\n",
      "Requirement already satisfied: wheel in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->deepseek_vl2==1.0.0) (0.45.1)\n",
      "Requirement already satisfied: cmake in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (3.31.6)\n",
      "Requirement already satisfied: lit in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from triton==2.0.0->torch==2.0.1->deepseek_vl2==1.0.0) (18.1.8)\n",
      "Requirement already satisfied: torchvision in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from timm>=0.9.16->deepseek_vl2==1.0.0) (0.15.2)\n",
      "Requirement already satisfied: psutil in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from accelerate->deepseek_vl2==1.0.0) (7.0.0)\n",
      "Requirement already satisfied: six in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from attrdict->deepseek_vl2==1.0.0) (1.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from jinja2->torch==2.0.1->deepseek_vl2==1.0.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from requests->transformers==4.38.2->deepseek_vl2==1.0.0) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from sympy->torch==2.0.1->deepseek_vl2==1.0.0) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/quynd/vidCapLLM/venv/lib/python3.11/site-packages (from torchvision->timm>=0.9.16->deepseek_vl2==1.0.0) (11.1.0)\n",
      "Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Building wheels for collected packages: deepseek_vl2\n",
      "  Building editable for deepseek_vl2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepseek_vl2: filename=deepseek_vl2-1.0.0-0.editable-py3-none-any.whl size=14672 sha256=2ee53b8f7ddbf57221372daf4a9c504ceea09ed7379b05fc34fda02d077fe2f2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vwbizmsl/wheels/c7/3a/be/2df7ced65a0650263c4048d2af8f4963bf95998ca4e8f893a2\n",
      "Successfully built deepseek_vl2\n",
      "Installing collected packages: tokenizers, transformers, deepseek_vl2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "  Attempting uninstall: deepseek_vl2\n",
      "    Found existing installation: deepseek_vl2 1.0.0\n",
      "    Uninstalling deepseek_vl2-1.0.0:\n",
      "      Successfully uninstalled deepseek_vl2-1.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed deepseek_vl2-1.0.0 tokenizers-0.15.2 transformers-4.38.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c7f575-1d73-4075-9a54-f3f20e98db75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee74b132-9c0c-40ab-b547-594aedd1b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quynd/vidCapLLM/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is above 3.10, patching the collections module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quynd/vidCapLLM/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add pad token = ['<｜▁pad▁｜>'] to the tokenizer\n",
      "<｜▁pad▁｜>:2\n",
      "Add image token = ['<image>'] to the tokenizer\n",
      "<image>:128815\n",
      "Add video token = ['<video>'] to the tokenizer\n",
      "<video>:128823\n",
      "Add grounding-related tokens = ['<|ref|>', '<|/ref|>', '<|det|>', '<|/det|>', '<|grounding|>'] to the tokenizer with input_ids\n",
      "<|ref|>:128816\n",
      "<|/ref|>:128817\n",
      "<|det|>:128818\n",
      "<|/det|>:128819\n",
      "<|grounding|>:128820\n",
      "Add chat tokens = ['<|User|>', '<|Assistant|>'] to the tokenizer with input_ids\n",
      "<|User|>:128821\n",
      "<|Assistant|>:128822\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from deepseek_vl2.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM\n",
    "from deepseek_vl2.utils.io import load_pil_images\n",
    "\n",
    "\n",
    "# specify the path to the model\n",
    "model_path = \"deepseek-ai/deepseek-vl2-tiny\"\n",
    "vl_chat_processor: DeepseekVLV2Processor = DeepseekVLV2Processor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer\n",
    "\n",
    "vl_gpt: DeepseekVLV2ForCausalLM = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad09145d-43e4-4151-904e-3cfed6fcc99e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_pil_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m conversation = [\n\u001b[32m      6\u001b[39m     {\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m<|User|>\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m<|Assistant|>\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     11\u001b[39m ]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# load images and prepare for inputs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m pil_images = \u001b[43mload_pil_images\u001b[49m(conversation)\n\u001b[32m     15\u001b[39m prepare_inputs = vl_chat_processor(\n\u001b[32m     16\u001b[39m     conversations=conversation,\n\u001b[32m     17\u001b[39m     images=pil_images,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m     system_prompt=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m ).to(vl_gpt.device)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mprepare_inputs\u001b[39m\u001b[33m\"\u001b[39m, prepare_inputs)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_pil_images' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "## single image conversation example\n",
    "## Please note that <|ref|> and <|/ref|> are designed specifically for the object localization feature. These special tokens are not required for normal conversations.\n",
    "## If you would like to experience the grounded captioning functionality (responses that include both object localization and reasoning), you need to add the special token <|grounding|> at the beginning of the prompt. Examples could be found in Figure 9 of our paper.\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"<|User|>\",\n",
    "        \"content\": \"Description for the video: <video>\", \n",
    "    },\n",
    "    {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
    "]\n",
    "\n",
    "# load images and prepare for inputs\n",
    "pil_images = load_pil_images(conversation)\n",
    "prepare_inputs = vl_chat_processor(\n",
    "    conversations=conversation,\n",
    "    images=pil_images,\n",
    "    video = torch.rand(4, 1280, dtype=torch.bfloat16),\n",
    "    force_batchify=True,\n",
    "    system_prompt=\"\"\n",
    ").to(vl_gpt.device)\n",
    "\n",
    "print(\"prepare_inputs\", prepare_inputs)\n",
    "\n",
    "# run image encoder to get the image embeddings\n",
    "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "\n",
    "print(inputs_embeds.shape)\n",
    "\n",
    "# run the model to get the response\n",
    "outputs = vl_gpt.language.generate(\n",
    "    inputs_embeds=inputs_embeds,\n",
    "    attention_mask=prepare_inputs.attention_mask,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=False)\n",
    "print(f\"{prepare_inputs['sft_format'][0]}\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c3bd02-8819-43c8-91e8-02f508e369bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37maircsrv5-Z690-Pro-RS            \u001b[m  Thu Mar 13 15:46:16 2025  \u001b[1m\u001b[30m550.120\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4080 SUPER\u001b[m |\u001b[31m 35°C\u001b[m, \u001b[32m  4 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  424\u001b[m / \u001b[33m16376\u001b[m MB | \u001b[1m\u001b[30maircsrv5\u001b[m(\u001b[33m249M\u001b[m) \u001b[1m\u001b[30maircsrv5\u001b[m(\u001b[33m71M\u001b[m) \u001b[1m\u001b[30maircsrv5\u001b[m(\u001b[33m64M\u001b[m) \u001b[1m\u001b[30maircsrv5\u001b[m(\u001b[33m18M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
